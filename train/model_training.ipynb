{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqxOD-7wjF3L"
      },
      "source": [
        "# Trabajo Fin de Grado - Ingeniería de Software\n",
        "## Entrenamiento del modelo de detección de expresiones faciales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependencias y montado de Google Drive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3-AG55Vi8BX",
        "outputId": "2557d91f-8fb0-4768-da8d-9916d4eec3c3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJDN08vbNvj8"
      },
      "outputs": [],
      "source": [
        "classes = {\n",
        "    0: \"Neutral\",\n",
        "    1: \"Happiness\",\n",
        "    2: \"Sadness\",\n",
        "    3: \"Surprise\",\n",
        "    4: \"Anger\", \n",
        "    #5: \"Fear\",\n",
        "    #6: \"Disgust\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwvkqxUHk3_S"
      },
      "outputs": [],
      "source": [
        "fer_classes = {\n",
        "    0: \"neutral\",\n",
        "    1: \"happy\",\n",
        "    2: \"sad\",\n",
        "    3: \"surprise\", \n",
        "    4: \"angry\",\n",
        "    #4: \"fear\",\n",
        "}\n",
        "\n",
        "fer_classes_cor = {\n",
        "    \"neutral\": \"Neutral\",\n",
        "    \"happy\": \"Happiness\",\n",
        "    \"sad\": \"Sadness\",\n",
        "    \"surprise\": \"Surprise\",\n",
        "    \"angry\": \"Anger\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8vPl_VyNvj9"
      },
      "outputs": [],
      "source": [
        "train_set_dir = './dataset/train_data'\n",
        "val_set_dir = './dataset/val_data'\n",
        "test_set_dir = './dataset/test_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbEoB0OSxqWK"
      },
      "outputs": [],
      "source": [
        "fer_train_set_dir = './dataset2/train'\n",
        "fer_val_set_dir = './dataset2/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KWPoOSojm3H"
      },
      "source": [
        "# Descargar FER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4_7CucJjpGh",
        "outputId": "84e6a73f-8146-473b-9796-0320179570b0"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp \"./gdrive/MyDrive/Colab Notebooks/Data/kaggle.json\" ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q -o challenges-in-representation-learning-facial-expression-recognition-challenge.zip -d ./tmp_dataset\n",
        "!tar -xf ./tmp_dataset/fer2013.tar.gz --directory ./tmp_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag6gBR_a6trt"
      },
      "source": [
        "## Mejora de las labels del dataset con FERPlus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWINFipW7USK",
        "outputId": "ffef416a-23d9-4a67-ea23-b64d406a42df"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/microsoft/FERPlus.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUKQGGag7Yjv",
        "outputId": "e7b1c9cc-01bc-4616-9c4c-fea52ac69b05"
      },
      "outputs": [],
      "source": [
        "!python FERPlus/src/generate_training_data.py -d tmp_dataset2 -fer ./tmp_dataset/fer2013/fer2013.csv -ferplus ./FERPlus/fer2013new.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffOKzblXFtr0"
      },
      "outputs": [],
      "source": [
        "!cp -r FERPlus/data/* tmp_dataset2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jYXc0MrE5nk"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "emotion_ferplus = ['neutral', 'happy', 'surprise', 'sad', 'angry', 'disgust', 'fear', 'contempt']\n",
        "\n",
        "os.system(f'mkdir ./dataset2')\n",
        "os.system(f'mkdir {fer_train_set_dir}')\n",
        "os.system(f'mkdir {fer_val_set_dir}')  \n",
        "for _e in emotion_ferplus:\n",
        "  os.system(f'mkdir {fer_val_set_dir}/{_e}')  \n",
        "  os.system(f'mkdir {fer_train_set_dir}/{_e}')\n",
        "\n",
        "\n",
        "for folder_name in ['FER2013Test', 'FER2013Train', 'FER2013Valid']:\n",
        "  in_label_path = os.path.join('./tmp_dataset2', folder_name, 'label.csv')\n",
        "  with open(in_label_path) as csvfile: \n",
        "    emotion_label = csv.reader(csvfile) \n",
        "    for row in emotion_label: \n",
        "      image_path = os.path.join('./tmp_dataset2', folder_name, row[0])\n",
        "\n",
        "      emotion_raw = list(map(float, row[2:len(row)]))\n",
        "      size = len(emotion_raw)\n",
        "      emotion_unknown     = [0.0] * size\n",
        "      emotion_unknown[-2] = 1.0\n",
        "\n",
        "      # Elimina las emociones con un solo \"voto\"\n",
        "      for i in range(size):\n",
        "        if emotion_raw[i] < 1.0 + sys.float_info.epsilon:\n",
        "          emotion_raw[i] = 0.0\n",
        "\n",
        "      sum_list = sum(emotion_raw)\n",
        "\n",
        "      # Encuentra la emocion con el mayor número de votos\n",
        "      maxval = max(emotion_raw) \n",
        "      if maxval > 0.5*sum_list: \n",
        "        emotion = np.argmax(emotion_raw)\n",
        "        dest = fer_val_set_dir if folder_name == 'FER2013Valid' else fer_train_set_dir\n",
        "        if(emotion <= len(emotion_ferplus) - 1):\n",
        "          os.system(f'mv {image_path} {dest}/{emotion_ferplus[emotion]}') \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms3oRDkOylqT",
        "outputId": "6f157531-457a-4ffa-ef1c-bd9effe0fbc4"
      },
      "outputs": [],
      "source": [
        "fer_class_count = {}\n",
        "fer_class_count_total = 0\n",
        "\n",
        "for directory in list(os.listdir(fer_train_set_dir)):\n",
        "  fer_class_count[directory] = len([name for name in os.listdir(os.path.join(fer_train_set_dir,directory))])\n",
        "  fer_class_count_total += fer_class_count[directory]\n",
        "\n",
        "for em, co in fer_class_count.items():\n",
        "  print(f\"{em}: {co/fer_class_count_total}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlGd1xWytT5c"
      },
      "outputs": [],
      "source": [
        "# Elimina todos los directorios que no se van a usar en el entrenamiento\n",
        "for directory in list(os.listdir(fer_train_set_dir)):\n",
        "  if(directory not in list(fer_classes.values())):\n",
        "    os.system(f'rm -r {os.path.join(fer_train_set_dir,directory)}') \n",
        "\n",
        "\n",
        "for directory in list(os.listdir(fer_val_set_dir)):\n",
        "  if(directory not in list(fer_classes.values())):\n",
        "    os.system(f'rm -r {os.path.join(fer_val_set_dir,directory)}') \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDPETYvFONm7"
      },
      "source": [
        "# Cargar Affectnet desde Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ5_kJJiv8ZJ"
      },
      "outputs": [],
      "source": [
        "!mkdir ./dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srxprKn8OS0I",
        "outputId": "4509b041-0047-443c-dc5f-75c1129c6d5a"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/TFG/affectnet_reduced/train_set.tar ./dataset/\n",
        "!cp /content/gdrive/MyDrive/TFG/affectnet_reduced/val_set.tar ./dataset/\n",
        "\n",
        "!tar -xf ./dataset/train_set.tar -C ./dataset/\n",
        "!tar -xf ./dataset/val_set.tar -C ./dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXfE4Sq1Nvj-"
      },
      "source": [
        "# Formateo de AffectNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNNJ_MuXULD_"
      },
      "outputs": [],
      "source": [
        "def prepare_data(input_dir, output_dir):\n",
        "    class_count = {}\n",
        "    class_count_total = 0\n",
        "\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "    for _c in classes.values():\n",
        "        os.mkdir(os.path.join(output_dir, _c))\n",
        "\n",
        "    if os.path.exists(os.path.join(input_dir, 'images')):\n",
        "      test_images_unorganized = list(os.listdir(os.path.join(input_dir, 'images')))\n",
        "      for _f in test_images_unorganized:\n",
        "          n_split = _f.split('.')[0]\n",
        "          folder = classes.get(int(np.load(os.path.join(input_dir, 'annotations', f'{n_split}_exp.npy'))), None)\n",
        "\n",
        "          if folder and os.path.exists(os.path.join(output_dir, folder)):\n",
        "            if not class_count.get(folder):\n",
        "              class_count[folder] = 0\n",
        "            class_count[folder] += 1\n",
        "            class_count_total += 1\n",
        "            os.system(f'cp {os.path.join(input_dir,\"images\", _f)} {os.path.join(output_dir, folder)}') \n",
        "    \n",
        "    return class_count, class_count_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Tll8jb4NvkA"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  os.system(f'rm -r {val_set_dir}')\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  os.system(f'rm -r {train_set_dir}')\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "prepare_data('./dataset/val_set/', val_set_dir)\n",
        "aff_class_count, aff_class_count_total = prepare_data('./dataset/train_set/', train_set_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHTdH51QBoKL"
      },
      "outputs": [],
      "source": [
        "for em, co in aff_class_count.items():\n",
        "  print(f\"{em}: {co/aff_class_count_total}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT56JsFVuPuz"
      },
      "source": [
        "# Creación del dataset de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsKFEcoRuTck"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "for directory in list(os.listdir(fer_train_set_dir)):\n",
        "  images = os.listdir(os.path.join(fer_train_set_dir, directory))\n",
        "  random.Random(1).shuffle(images)\n",
        "  tests_samples = images[int((len(images)+1)*.80):]\n",
        "  os.system(f'mkdir {os.path.join(test_set_dir)}') \n",
        "  os.system(f'mkdir {os.path.join(test_set_dir, fer_classes_cor[directory])}') \n",
        "\n",
        "  for img in tests_samples:\n",
        "    os.system(f'mv {os.path.join(fer_train_set_dir,directory,img)} {os.path.join(test_set_dir, fer_classes_cor.get(directory))}/') \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2BpTlLz6V45"
      },
      "source": [
        "# Combinado de los datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w04cBRS46XrT"
      },
      "outputs": [],
      "source": [
        "for directory in list(os.listdir(fer_train_set_dir)):\n",
        "  os.system(f'mv {os.path.join(fer_train_set_dir,directory)}/* {os.path.join(train_set_dir, fer_classes_cor.get(directory))}/') \n",
        "\n",
        "for directory in list(os.listdir(fer_val_set_dir)):\n",
        "  os.system(f'mv {os.path.join(fer_val_set_dir,directory)}/* {os.path.join(val_set_dir, fer_classes_cor.get(directory))}/') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XApRpuZ_jWKl"
      },
      "source": [
        "# Constantes de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS8htWgrjXb_"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 224, 224\n",
        "input_shape = (img_width, img_height, 1)\n",
        "batch_size = 64\n",
        "\n",
        "class_names = list(classes.values())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Remm02oFjcQ9"
      },
      "source": [
        "## Visualizando los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhBAQqHc8tIr"
      },
      "source": [
        "## Preparación de los datos para optimización de hiper parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MImyj10qH4m3",
        "outputId": "9c2cfada-1ab8-4713-fa91-cc904f6e87e9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "search_x = []\n",
        "search_y = []\n",
        "\n",
        "\n",
        "\n",
        "for directory in list(os.listdir(val_set_dir)):\n",
        "  images = os.listdir(os.path.join(val_set_dir, directory))\n",
        "  for img in images:\n",
        "    img_np = cv2.imread(os.path.join(val_set_dir, directory, img))\n",
        "    img_np = cv2.resize(img_np, (img_width, img_height))\n",
        "    img_np = cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY)\n",
        "    search_x.append(img_np)\n",
        "    search_y.append(directory)\n",
        "\n",
        "search_x = np.asarray(search_x)\n",
        "search_y = np.asarray(search_y)\n",
        "\n",
        "search_x = search_x.reshape(-1, img_width, img_height, 1)\n",
        "\n",
        "search_x.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "UIet4eu2j1el",
        "outputId": "9ebeede1-0485-4830-c6cc-b9b9e6bbcf0d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_set_dir, labels='inferred', label_mode='categorical',\n",
        "    class_names=class_names, color_mode='rgb', batch_size=batch_size, image_size=(img_width, img_height)\n",
        "    , shuffle=True, seed=None, validation_split=None, subset=None,\n",
        "    interpolation='bilinear', follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "val_ds = image_dataset_from_directory(\n",
        "    val_set_dir, labels='inferred', label_mode='categorical',\n",
        "    class_names=class_names, color_mode='rgb', batch_size=batch_size, image_size=(img_width, img_height)\n",
        "    , shuffle=True, seed=None, validation_split=None, subset=None,\n",
        "    interpolation='bilinear', follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "test_ds = image_dataset_from_directory(\n",
        "    test_set_dir, labels='inferred', label_mode='categorical',\n",
        "    class_names=class_names, color_mode='rgb', batch_size=batch_size, image_size=(img_width, img_height)\n",
        "    , shuffle=True, seed=None, validation_split=None, subset=None,\n",
        "    interpolation='bilinear', follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=batch_size)\n",
        "val_ds = val_ds.prefetch(buffer_size=batch_size)\n",
        "test_ds = test_ds.prefetch(buffer_size=batch_size)\n",
        "\n",
        "sample_size = 25\n",
        "cols = 5\n",
        "rows = sample_size // cols\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for images, labels in val_ds.take(1):\n",
        "    for i in range(sample_size):\n",
        "        img = images[i].numpy() / 255.0\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(img)\n",
        "        plt.title(class_names[np.argmax(labels[i])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pesos de las clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZKJ8e4wDnXH"
      },
      "outputs": [],
      "source": [
        "final_class_count = {}\n",
        "final_class_count_total = 0\n",
        "class_weights = {}\n",
        "\n",
        "for directory in list(os.listdir(train_set_dir)):\n",
        "  final_class_count[directory] = len([name for name in os.listdir(os.path.join(train_set_dir,directory))])\n",
        "  final_class_count_total += final_class_count[directory]\n",
        "\n",
        "for i, _c in enumerate(class_names):\n",
        "  class_weights[i] = final_class_count_total / (len(class_names) * final_class_count[_c])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkLvt60QhuAa"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "sfF_QC2fhwL3",
        "outputId": "bc284e17-8bb5-4c49-c27b-0654c919b05f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "augmentation = Sequential ([\n",
        "  Resizing(img_width, img_height),\n",
        "  Rescaling(1./255),\n",
        "  RandomFlip(\"horizontal\"),\n",
        "  RandomRotation(0.2),\n",
        "]) \n",
        "\n",
        "\n",
        "sample_size = 16\n",
        "cols = 4\n",
        "rows = sample_size // cols\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(sample_size):\n",
        "        augmented_images = augmentation(images)\n",
        "        img = augmented_images[0].numpy()\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BGw0Qe5j34N"
      },
      "source": [
        "## Definición del modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW4pQ2tvj57d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "def create_model(learning_rate=0.001, dense_units=128, dropout1=0.3, dropout2=0.25, n_channels=1, num_classes=3):\n",
        "  \n",
        "    m = Sequential([\n",
        "      augmentation,\n",
        "      Conv2D(32, (3, 3), input_shape=(img_width, img_height,n_channels), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Conv2D(32, (3, 3), input_shape=(img_width, img_height,n_channels), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      MaxPooling2D(pool_size=(2,2)),\n",
        "      Dropout(dropout1),\n",
        "\n",
        "      Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      MaxPooling2D(pool_size=(2,2)),\n",
        "      Dropout(dropout1),\n",
        "\n",
        "      Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      MaxPooling2D(pool_size=(2,2)),\n",
        "      Dropout(dropout1),\n",
        "\n",
        "      Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      MaxPooling2D(pool_size=(2,2)),\n",
        "      Dropout(dropout1),\n",
        "\n",
        "\n",
        "      Conv2D(512, (3, 3), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Conv2D(512, (3, 3), padding='same', activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      MaxPooling2D(pool_size=(2,2)),\n",
        "      Dropout(dropout1),\n",
        "\n",
        "      Flatten(),\n",
        "      Dense(dense_units, activation = \"relu\"),\n",
        "      BatchNormalization(),\n",
        "      Dropout(dropout2),\n",
        "\n",
        "      Dense(dense_units / 2, activation = \"relu\"),\n",
        "      BatchNormalization(),\n",
        "      Dropout(dropout2),\n",
        "\n",
        "      Dense(num_classes, activation = \"softmax\"),\n",
        "\n",
        "    ]) \n",
        "\n",
        "    m.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])    # TODO: Compilación del modelo\n",
        "\n",
        "    return m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtV8RTtoEaXU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import *\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_model_transfer(num_classes=3):\n",
        "    m_base = tf.keras.applications.InceptionV3(weights='imagenet',include_top=False,input_shape=(img_width, img_height, 3))\n",
        "    #for layer in m_base.layers[:30]:\n",
        "      #layer.trainable = False\n",
        "\n",
        "\n",
        "    #for (i,layer) in enumerate(m_base.layers):\n",
        "      #print(str(i),layer.__class__.__name__,layer.trainable)\n",
        "\n",
        "    m_base.trainable = False\n",
        "\n",
        "    def addTopModelMobileNet(bottom_model):\n",
        "        \"\"\"creates the top or head of the model that will be \n",
        "        placed ontop of the bottom layers\"\"\"\n",
        "\n",
        "        top_model = bottom_model.output\n",
        "\n",
        "        top_model = Flatten()(top_model)\n",
        "        top_model = Dropout(0.5)(top_model)\n",
        "        top_model = Dense(4096,activation='relu')(top_model)\n",
        "        top_model = Dropout(0.5)(top_model)\n",
        "        top_model = Dense(1024,activation='relu')(top_model)\n",
        "        top_model = Dropout(0.5)(top_model)\n",
        "        top_model = Dense(num_classes,activation='softmax')(top_model)\n",
        "\n",
        "        return top_model\n",
        "\n",
        "    FC_Head = addTopModelMobileNet(m_base)\n",
        "\n",
        "    m_tmp = Model(inputs = m_base.input, outputs = FC_Head)\n",
        "    m = Sequential([\n",
        "      augmentation,\n",
        "      m_tmp\n",
        "    ])\n",
        "\n",
        "    m.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy']) \n",
        "    \n",
        "    return m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjQnbfxcQSc0",
        "outputId": "c807d777-4ef4-498f-ca90-3c65bfc8f870"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/vmarichkav/keras-vggface.git\n",
        "!pip install keras_applications --no-deps\n",
        "\n",
        "from tensorflow.keras.optimizers import *\n",
        "from keras_vggface.vggface import VGGFace\n",
        "\n",
        "def create_model_resnet(num_classes):\n",
        "    resnet_model = VGGFace(model='resnet50', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "    for layer in resnet_model.layers:\n",
        "        if not isinstance(layer, BatchNormalization):\n",
        "            layer.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        augmentation,\n",
        "        resnet_model,\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YYOzoZCkDYa"
      },
      "source": [
        "## Entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678IXSE_cAto",
        "outputId": "a459a2c3-5a7f-497c-8292-dfa91548428e"
      },
      "outputs": [],
      "source": [
        "# Ejecutar para eliminar los checkpoints de una ejecución anterior\n",
        "!rm -r /content/gdrive/MyDrive/TFG/checkpoints-fer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm7UFPay8Z3o"
      },
      "source": [
        "## Búsqueda de hiper parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEZ8gedomv1B"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# Semilla aleatoria\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# Modelo\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=batch_size, verbose=1)\n",
        "\n",
        "#learning_rate = [0.001, 0.01, 0.1] # 0.001\n",
        "#dense_units = [128, 64, 256] # 128\n",
        "#dropout1 = [0.5, 0.25, 0.1]\n",
        "#dropout2 = [0.5, 0.25, 0.1]\n",
        "\n",
        "learning_rate = [0.001, 0.1] # 0.001\n",
        "dense_units = [64, 256] # 128\n",
        "dropout1 = [0.1, 0.5]\n",
        "dropout2 = [0.1, 0.5]\n",
        "\n",
        "\n",
        "param_grid = dict(learning_rate=learning_rate, dense_units=dense_units, dropout1=dropout1, dropout2=dropout2)\n",
        "\n",
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_jobs=None, cv=5)\n",
        "\n",
        "grid_result = grid.fit(search_x, search_y)\n",
        "\n",
        "# Resultados\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzh0Vqycd1-f",
        "outputId": "f5ca2ede-6f6f-4b36-a802-137b9316eb88"
      },
      "outputs": [],
      "source": [
        "#model = create_model_transfer(num_classes=len(class_names))\n",
        "model = create_model(num_classes=len(class_names))\n",
        "#model = create_model_resnet(num_classes=len(class_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULfBroqs7luv"
      },
      "source": [
        "### Celda para cargar un modelo entrenado anteriormente con Transfer Learning para hacer fine tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sOo20k4FXZj",
        "outputId": "13cf5013-6e69-4eec-d5c6-4c5f9014dbed"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/MyDrive/TFG/checkpoints-5-inceptionv3/model-18-0.70.hdf5')\n",
        "model.trainable = True\n",
        "K.set_value(model.optimizer.learning_rate, 0.00001)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBITK5Q98QVM"
      },
      "source": [
        "### Celda para cargar un modelo entrenado anteriormente para seguir el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1psASkDUD38t"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/MyDrive/TFG/checkpointsc/model-32-0.59.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comenzar entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXvRsOT7kHwd",
        "outputId": "6a0d4de8-b049-465d-fd94-e05e0d0b4e3e"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "from datetime import datetime\n",
        "\n",
        "logdir = \"/content/gdrive/MyDrive/TFG/logs/checkpoint-3-inception-test\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "  \"/content/gdrive/MyDrive/TFG/checkpoints-3-inception-test/model-{epoch:02d}-{val_accuracy:.2f}.hdf5\",\n",
        "  monitor='val_accuracy',\n",
        "  verbose=1,\n",
        "  save_best_only=True, \n",
        "  mode='max'\n",
        ")\n",
        "\n",
        "earlystop = EarlyStopping(\n",
        "  monitor='val_accuracy',\n",
        "  min_delta=0,\n",
        "  patience=6,\n",
        "  verbose=1,\n",
        "  restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "  monitor='val_accuracy',\n",
        "  factor=0.95,\n",
        "  patience=3,\n",
        "  verbose=1,\n",
        "  min_delta=0.0001\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=100,\n",
        "    validation_data=val_ds,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[checkpoint, earlystop, reduce_lr, tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2ICuP8Zko3R"
      },
      "source": [
        "## Guardando el modelo\n",
        "\n",
        "Guardamos el modelo con sus pesos entrenados en nuestro Google Drive. Es importante que la ruta de destino exista en drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Otn5oa3qmb82"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "path = './gdrive/MyDrive/modelos_ml/vico_practica2.h5' \n",
        "model.summary()\n",
        "model.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQglKAWDkdln"
      },
      "source": [
        "## Evolución de las métricas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Qdm_wICgkfUp",
        "outputId": "24ce97d6-c02a-45a0-d304-1e707dae8cb5"
      },
      "outputs": [],
      "source": [
        "def show_training_graph(data):\n",
        "  acc = data.history['accuracy']\n",
        "  val_acc = data.history['val_accuracy']\n",
        "  loss = data.history['loss']\n",
        "  val_loss = data.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "  plt.figure(figsize=(11, 8))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.grid(True)\n",
        "  plt.plot(epochs, acc, label='Training Accuracy')\n",
        "  plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "  plt.title('Evolución de la precisión en entrenamiento y validación')\n",
        "  plt.legend(loc='lower right')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.grid(True)\n",
        "  plt.plot(epochs, loss, label='Training Loss')\n",
        "  plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "  plt.title('Evolución de loss en entrenamiento y validación')\n",
        "  plt.legend(loc='upper right')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "show_training_graph(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvSvPdHwxrdf"
      },
      "source": [
        "## Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQN7eKwYG_3P"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1fZNMNwTTOK"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "predictions_labels = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generación de tabla de predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GtsLOAhUxq6_",
        "outputId": "4e61fe4f-cb04-4f6f-e769-eae685441f1f"
      },
      "outputs": [],
      "source": [
        "sample_size = 60\n",
        "cols = 5\n",
        "rows = sample_size // cols\n",
        "\n",
        "plt.figure(figsize=(cols * 3, rows * 4))\n",
        "\n",
        "for images, labels in test_ds.take(1):\n",
        "  for i in range(sample_size):\n",
        "    img = images[i].numpy()\n",
        "    img = img.reshape((1,) + img.shape)\n",
        "    prediction = np.argmax(model.predict(img, batch_size=1)[0])\n",
        "    predictions.append(class_names[prediction])\n",
        "    predictions_labels.append(class_names[np.argmax(labels[i])])\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(img[0]/255)\n",
        "    plt.title(f'Pred: {class_names[prediction]}\\nReal: {class_names[np.argmax(labels[i])]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IrnZ7EiMg6C"
      },
      "source": [
        "# Matriz de confusión relativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "aAq1jsQ_Mf-a",
        "outputId": "8abf6e22-851d-48f8-b9c5-cd35e7d6e968"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "cf = confusion_matrix(predictions_labels, predictions)\n",
        "cf = cf.astype('float') / cf.sum(axis=1)[:, np.newaxis]\n",
        "print(cf)\n",
        "cf = pd.DataFrame(cf, class_names,class_names)\n",
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "sns.heatmap(cf, annot=True, annot_kws={\"size\": 12}, fmt='.2%')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "test_tf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "macml-kernel",
      "language": "python",
      "name": "macml-kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
